Some weights of the model checkpoint at /data/users/cboned/checkpoints/VIT_imagenet100_first_train_reduced.pt were not used when initializing ViTForImageClassification: ['vit.encoder.layer.1.attention.attention.key.bias', 'vit.encoder.layer.1.attention.attention.key.weight', 'vit.encoder.layer.1.attention.attention.query.bias', 'vit.encoder.layer.1.attention.attention.query.weight', 'vit.encoder.layer.1.attention.attention.value.bias', 'vit.encoder.layer.1.attention.attention.value.weight', 'vit.encoder.layer.1.attention.output.dense.bias', 'vit.encoder.layer.1.attention.output.dense.weight', 'vit.encoder.layer.1.intermediate.dense.bias', 'vit.encoder.layer.1.intermediate.dense.weight', 'vit.encoder.layer.1.layernorm_after.bias', 'vit.encoder.layer.1.layernorm_after.weight', 'vit.encoder.layer.1.layernorm_before.bias', 'vit.encoder.layer.1.layernorm_before.weight', 'vit.encoder.layer.1.output.dense.bias', 'vit.encoder.layer.1.output.dense.weight', 'vit.encoder.layer.10.attention.attention.key.bias', 'vit.encoder.layer.10.attention.attention.key.weight', 'vit.encoder.layer.10.attention.attention.query.bias', 'vit.encoder.layer.10.attention.attention.query.weight', 'vit.encoder.layer.10.attention.attention.value.bias', 'vit.encoder.layer.10.attention.attention.value.weight', 'vit.encoder.layer.10.attention.output.dense.bias', 'vit.encoder.layer.10.attention.output.dense.weight', 'vit.encoder.layer.10.intermediate.dense.bias', 'vit.encoder.layer.10.intermediate.dense.weight', 'vit.encoder.layer.10.layernorm_after.bias', 'vit.encoder.layer.10.layernorm_after.weight', 'vit.encoder.layer.10.layernorm_before.bias', 'vit.encoder.layer.10.layernorm_before.weight', 'vit.encoder.layer.10.output.dense.bias', 'vit.encoder.layer.10.output.dense.weight', 'vit.encoder.layer.11.attention.attention.key.bias', 'vit.encoder.layer.11.attention.attention.key.weight', 'vit.encoder.layer.11.attention.attention.query.bias', 'vit.encoder.layer.11.attention.attention.query.weight', 'vit.encoder.layer.11.attention.attention.value.bias', 'vit.encoder.layer.11.attention.attention.value.weight', 'vit.encoder.layer.11.attention.output.dense.bias', 'vit.encoder.layer.11.attention.output.dense.weight', 'vit.encoder.layer.11.intermediate.dense.bias', 'vit.encoder.layer.11.intermediate.dense.weight', 'vit.encoder.layer.11.layernorm_after.bias', 'vit.encoder.layer.11.layernorm_after.weight', 'vit.encoder.layer.11.layernorm_before.bias', 'vit.encoder.layer.11.layernorm_before.weight', 'vit.encoder.layer.11.output.dense.bias', 'vit.encoder.layer.11.output.dense.weight', 'vit.encoder.layer.2.attention.attention.key.bias', 'vit.encoder.layer.2.attention.attention.key.weight', 'vit.encoder.layer.2.attention.attention.query.bias', 'vit.encoder.layer.2.attention.attention.query.weight', 'vit.encoder.layer.2.attention.attention.value.bias', 'vit.encoder.layer.2.attention.attention.value.weight', 'vit.encoder.layer.2.attention.output.dense.bias', 'vit.encoder.layer.2.attention.output.dense.weight', 'vit.encoder.layer.2.intermediate.dense.bias', 'vit.encoder.layer.2.intermediate.dense.weight', 'vit.encoder.layer.2.layernorm_after.bias', 'vit.encoder.layer.2.layernorm_after.weight', 'vit.encoder.layer.2.layernorm_before.bias', 'vit.encoder.layer.2.layernorm_before.weight', 'vit.encoder.layer.2.output.dense.bias', 'vit.encoder.layer.2.output.dense.weight', 'vit.encoder.layer.3.attention.attention.key.bias', 'vit.encoder.layer.3.attention.attention.key.weight', 'vit.encoder.layer.3.attention.attention.query.bias', 'vit.encoder.layer.3.attention.attention.query.weight', 'vit.encoder.layer.3.attention.attention.value.bias', 'vit.encoder.layer.3.attention.attention.value.weight', 'vit.encoder.layer.3.attention.output.dense.bias', 'vit.encoder.layer.3.attention.output.dense.weight', 'vit.encoder.layer.3.intermediate.dense.bias', 'vit.encoder.layer.3.intermediate.dense.weight', 'vit.encoder.layer.3.layernorm_after.bias', 'vit.encoder.layer.3.layernorm_after.weight', 'vit.encoder.layer.3.layernorm_before.bias', 'vit.encoder.layer.3.layernorm_before.weight', 'vit.encoder.layer
- This IS expected if you are initializing ViTForImageClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing ViTForImageClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
CREATING THE BASELINE METRIC VALUE
 STARTING TO EVALUATE FO THE FIRST TIME
val Procedure: 24it [00:10,  2.21it/s]
Training Procedure: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 990/990 [32:02<00:00, 1.94s/batch]
Validation Loss Epoch: 0 Value: 9.23502799987793 Optimal_loss: 9.23502799987793
val Procedure: 24it [00:12,  1.86it/s]████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 990/990 [32:02<00:00, 1.41s/batch]
Loss Epoch: 1 Value: 9.21966341962718
Training Procedure: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 990/990 [23:21<00:00, 1.42s/batch]
Model Updated: Validation Loss Epoch: 0 Value: 9.20949104309082 Optimal_loss: 9.20949104309082
val Procedure: 24it [00:13,  1.74it/s]████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 990/990 [23:21<00:00, 1.28s/batch]
Loss Epoch: 2 Value: 9.208630405772816
Training Procedure: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 990/990 [23:20<00:00, 1.41s/batch]
val Procedure: 24it [00:09,  2.51it/s]████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 990/990 [23:20<00:00, 1.28s/batch]
Loss Epoch: 3 Value: 9.207188849978976
Training Procedure: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 990/990 [23:21<00:00, 1.42s/batch]
val Procedure: 24it [00:11,  2.12it/s]████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 990/990 [23:20<00:00, 1.28s/batch]
Loss Epoch: 4 Value: 9.205133540220935
Training Procedure: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 990/990 [23:21<00:00, 1.42s/batch]
val Procedure: 24it [00:14,  1.68it/s]████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 990/990 [23:21<00:00, 1.28s/batch]
Loss Epoch: 5 Value: 9.163650238152707
Training Procedure: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 990/990 [23:19<00:00, 1.41s/batch]
Model Updated: Validation Loss Epoch: 0 Value: 9.09321491241455 Optimal_loss: 9.09321491241455
val Procedure: 24it [00:10,  2.27it/s]████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 990/990 [23:19<00:00, 1.28s/batch]
Loss Epoch: 6 Value: 9.086745764029146
Training Procedure: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 990/990 [25:14<00:00, 1.53s/batch]
Model Updated: Validation Loss Epoch: 0 Value: 8.989054679870605 Optimal_loss: 8.989054679870605
val Procedure: 24it [00:15,  1.51it/s]████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 990/990 [25:14<00:00, 1.55s/batch]
Loss Epoch: 7 Value: 9.013152689885612
Training Procedure: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 990/990 [28:10<00:00, 1.71s/batch]
Model Updated: Validation Loss Epoch: 0 Value: 8.937400512695312 Optimal_loss: 8.937400512695312
val Procedure: 24it [00:13,  1.80it/s]████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 990/990 [28:10<00:00, 1.28s/batch]
Loss Epoch: 8 Value: 8.812369095195423
Training Procedure: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 990/990 [23:22<00:00, 1.42s/batch]
Model Updated: Validation Loss Epoch: 0 Value: 8.680840167999268 Optimal_loss: 8.680840167999268
val Procedure: 24it [00:09,  2.47it/s]████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 990/990 [23:22<00:00, 1.28s/batch]
Loss Epoch: 9 Value: 8.64953389215951
Training Procedure: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 990/990 [23:30<00:00, 1.42s/batch]
Model Updated: Validation Loss Epoch: 0 Value: 8.620057926177978 Optimal_loss: 8.620057926177978
val Procedure: 24it [00:13,  1.82it/s]████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 990/990 [23:29<00:00, 1.56s/batch]
Loss Epoch: 10 Value: 8.556696634581595
Training Procedure: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 990/990 [26:25<00:00, 1.60s/batch]
Model Updated: Validation Loss Epoch: 0 Value: 8.51837459564209 Optimal_loss: 8.51837459564209
val Procedure: 24it [00:11,  2.14it/s]████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 990/990 [26:25<00:00, 1.28s/batch]
Loss Epoch: 11 Value: 8.48983712437177
Training Procedure:  29%|██████████████████████████████████████▉                                                                                              | 290/990 [06:52<16:34, 1.42s/batch]
Model Updated: Validation Loss Epoch: 0 Value: 8.465395851135254 Optimal_loss: 8.465395851135254
Traceback (most recent call last):                                                                                                                                                                
  File "/home/cboned/Projects/OCR-Koopman/main_classification_ode_distillation.py", line 217, in <module>
    main(cfg=cfg)
  File "/home/cboned/Projects/OCR-Koopman/main_classification_ode_distillation.py", line 134, in main
    _, train_loss = train_classification_task_distillation(
  File "/home/cboned/Projects/OCR-Koopman/train.py", line 252, in train_classification_task_distillation
    loss_final.backward()
  File "/home/cboned/miniconda3/envs/graphocr/lib/python3.10/site-packages/torch/_tensor.py", line 581, in backward
    torch.autograd.backward(
  File "/home/cboned/miniconda3/envs/graphocr/lib/python3.10/site-packages/torch/autograd/__init__.py", line 347, in backward
    _engine_run_backward(
  File "/home/cboned/miniconda3/envs/graphocr/lib/python3.10/site-packages/torch/autograd/graph.py", line 825, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt
