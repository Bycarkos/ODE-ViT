Some weights of the model checkpoint at /data/users/cboned/checkpoints/VIT_imagenet100_first_train_reduced.pt were not used when initializing ViTForImageClassification: ['vit.encoder.layer.1.attention.attention.key.bias', 'vit.encoder.layer.1.attention.attention.key.weight', 'vit.encoder.layer.1.attention.attention.query.bias', 'vit.encoder.layer.1.attention.attention.query.weight', 'vit.encoder.layer.1.attention.attention.value.bias', 'vit.encoder.layer.1.attention.attention.value.weight', 'vit.encoder.layer.1.attention.output.dense.bias', 'vit.encoder.layer.1.attention.output.dense.weight', 'vit.encoder.layer.1.intermediate.dense.bias', 'vit.encoder.layer.1.intermediate.dense.weight', 'vit.encoder.layer.1.layernorm_after.bias', 'vit.encoder.layer.1.layernorm_after.weight', 'vit.encoder.layer.1.layernorm_before.bias', 'vit.encoder.layer.1.layernorm_before.weight', 'vit.encoder.layer.1.output.dense.bias', 'vit.encoder.layer.1.output.dense.weight', 'vit.encoder.layer.10.attention.attention.key.bias', 'vit.encoder.layer.10.attention.attention.key.weight', 'vit.encoder.layer.10.attention.attention.query.bias', 'vit.encoder.layer.10.attention.attention.query.weight', 'vit.encoder.layer.10.attention.attention.value.bias', 'vit.encoder.layer.10.attention.attention.value.weight', 'vit.encoder.layer.10.attention.output.dense.bias', 'vit.encoder.layer.10.attention.output.dense.weight', 'vit.encoder.layer.10.intermediate.dense.bias', 'vit.encoder.layer.10.intermediate.dense.weight', 'vit.encoder.layer.10.layernorm_after.bias', 'vit.encoder.layer.10.layernorm_after.weight', 'vit.encoder.layer.10.layernorm_before.bias', 'vit.encoder.layer.10.layernorm_before.weight', 'vit.encoder.layer.10.output.dense.bias', 'vit.encoder.layer.10.output.dense.weight', 'vit.encoder.layer.11.attention.attention.key.bias', 'vit.encoder.layer.11.attention.attention.key.weight', 'vit.encoder.layer.11.attention.attention.query.bias', 'vit.encoder.layer.11.attention.attention.query.weight', 'vit.encoder.layer.11.attention.attention.value.bias', 'vit.encoder.layer.11.attention.attention.value.weight', 'vit.encoder.layer.11.attention.output.dense.bias', 'vit.encoder.layer.11.attention.output.dense.weight', 'vit.encoder.layer.11.intermediate.dense.bias', 'vit.encoder.layer.11.intermediate.dense.weight', 'vit.encoder.layer.11.layernorm_after.bias', 'vit.encoder.layer.11.layernorm_after.weight', 'vit.encoder.layer.11.layernorm_before.bias', 'vit.encoder.layer.11.layernorm_before.weight', 'vit.encoder.layer.11.output.dense.bias', 'vit.encoder.layer.11.output.dense.weight', 'vit.encoder.layer.2.attention.attention.key.bias', 'vit.encoder.layer.2.attention.attention.key.weight', 'vit.encoder.layer.2.attention.attention.query.bias', 'vit.encoder.layer.2.attention.attention.query.weight', 'vit.encoder.layer.2.attention.attention.value.bias', 'vit.encoder.layer.2.attention.attention.value.weight', 'vit.encoder.layer.2.attention.output.dense.bias', 'vit.encoder.layer.2.attention.output.dense.weight', 'vit.encoder.layer.2.intermediate.dense.bias', 'vit.encoder.layer.2.intermediate.dense.weight', 'vit.encoder.layer.2.layernorm_after.bias', 'vit.encoder.layer.2.layernorm_after.weight', 'vit.encoder.layer.2.layernorm_before.bias', 'vit.encoder.layer.2.layernorm_before.weight', 'vit.encoder.layer.2.output.dense.bias', 'vit.encoder.layer.2.output.dense.weight', 'vit.encoder.layer.3.attention.attention.key.bias', 'vit.encoder.layer.3.attention.attention.key.weight', 'vit.encoder.layer.3.attention.attention.query.bias', 'vit.encoder.layer.3.attention.attention.query.weight', 'vit.encoder.layer.3.attention.attention.value.bias', 'vit.encoder.layer.3.attention.attention.value.weight', 'vit.encoder.layer.3.attention.output.dense.bias', 'vit.encoder.layer.3.attention.output.dense.weight', 'vit.encoder.layer.3.intermediate.dense.bias', 'vit.encoder.layer.3.intermediate.dense.weight', 'vit.encoder.layer.3.layernorm_after.bias', 'vit.encoder.layer.3.layernorm_after.weight', 'vit.encoder.layer.3.layernorm_before.bias', 'vit.encoder.layer.3.layernorm_before.weight', 'vit.encoder.layer
- This IS expected if you are initializing ViTForImageClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing ViTForImageClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
CREATING THE BASELINE METRIC VALUE
 STARTING TO EVALUATE FO THE FIRST TIME
val Procedure: 24it [00:01, 12.03it/s]
Training Procedure: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 495/495 [15:52<00:00,  1.92s/it]
Validation Loss Epoch: 0 Value: 4.724906597137451 Optimal_loss: 4.724906597137451
val Procedure: 24it [00:01, 14.16it/s]████████████████████████████████████████████████████████████████████████████████████████████| 495/495 [15:52<00:00,  1.79s/it]
Loss Epoch: 1 Value: 4.689790420339565
Training Procedure: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 495/495 [15:39<00:00,  1.90s/it]
Model Updated: Validation Loss Epoch: 0 Value: 4.648453464508057 Optimal_loss: 4.648453464508057
val Procedure: 24it [00:01, 18.68it/s]████████████████████████████████████████████████████████████████████████████████████████████| 495/495 [15:38<00:00,  1.80s/it]
Loss Epoch: 2 Value: 4.612732808276861
Training Procedure: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 495/495 [15:37<00:00,  1.89s/it]
Model Updated: Validation Loss Epoch: 0 Value: 4.598474235534668 Optimal_loss: 4.598474235534668
val Procedure: 24it [00:01, 12.64it/s]████████████████████████████████████████████████████████████████████████████████████████████| 495/495 [15:37<00:00,  1.79s/it]
Loss Epoch: 3 Value: 4.577391542569555
Training Procedure: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 495/495 [15:34<00:00,  1.89s/it]
Model Updated: Validation Loss Epoch: 0 Value: 4.573597583770752 Optimal_loss: 4.573597583770752
val Procedure: 24it [00:01, 18.44it/s]████████████████████████████████████████████████████████████████████████████████████████████| 495/495 [15:33<00:00,  1.79s/it]
Loss Epoch: 4 Value: 4.540627878362482
Training Procedure: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 495/495 [15:38<00:00,  1.90s/it]
Model Updated: Validation Loss Epoch: 0 Value: 4.543937282562256 Optimal_loss: 4.543937282562256
val Procedure: 24it [00:01, 16.91it/s]████████████████████████████████████████████████████████████████████████████████████████████| 495/495 [15:38<00:00,  1.77s/it]
Loss Epoch: 5 Value: 4.489066071943803
Training Procedure: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 495/495 [15:35<00:00,  1.89s/it]
Model Updated: Validation Loss Epoch: 0 Value: 4.4995366477966305 Optimal_loss: 4.4995366477966305
val Procedure: 24it [00:01, 17.87it/s]████████████████████████████████████████████████████████████████████████████████████████████| 495/495 [15:34<00:00,  1.79s/it]
Loss Epoch: 6 Value: 4.420816408022485
Training Procedure: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 495/495 [15:42<00:00,  1.90s/it]
Model Updated: Validation Loss Epoch: 0 Value: 4.4101240348815915 Optimal_loss: 4.4101240348815915
val Procedure: 24it [00:01, 18.48it/s]████████████████████████████████████████████████████████████████████████████████████████████| 495/495 [15:42<00:00,  1.79s/it]
Loss Epoch: 7 Value: 4.348351971790044
Training Procedure: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 495/495 [15:34<00:00,  1.89s/it]
Model Updated: Validation Loss Epoch: 0 Value: 4.307286987304687 Optimal_loss: 4.307286987304687
val Procedure: 24it [00:01, 17.22it/s]████████████████████████████████████████████████████████████████████████████████████████████| 495/495 [15:34<00:00,  1.81s/it]
Loss Epoch: 8 Value: 4.249835002783573
Training Procedure: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 495/495 [15:36<00:00,  1.89s/it]
Model Updated: Validation Loss Epoch: 0 Value: 4.209727516174317 Optimal_loss: 4.209727516174317
val Procedure: 24it [00:01, 16.44it/s]████████████████████████████████████████████████████████████████████████████████████████████| 495/495 [15:36<00:00,  1.79s/it]
Loss Epoch: 9 Value: 4.238110259084991
Training Procedure: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 495/495 [15:34<00:00,  1.89s/it]
Model Updated: Validation Loss Epoch: 0 Value: 4.201423816680908 Optimal_loss: 4.201423816680908
val Procedure: 24it [00:01, 17.81it/s]████████████████████████████████████████████████████████████████████████████████████████████| 495/495 [15:34<00:00,  1.79s/it]
Loss Epoch: 10 Value: 4.2136439795445915
Training Procedure: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 495/495 [15:34<00:00,  1.89s/it]
val Procedure: 24it [00:01, 14.69it/s]████████████████████████████████████████████████████████████████████████████████████████████| 495/495 [15:34<00:00,  1.79s/it]
Loss Epoch: 11 Value: 4.144634209257184
Training Procedure: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 495/495 [15:36<00:00,  1.89s/it]
val Procedure: 24it [00:01, 15.45it/s]████████████████████████████████████████████████████████████████████████████████████████████| 495/495 [15:35<00:00,  1.79s/it]
Loss Epoch: 12 Value: 4.123504093439892
Training Procedure: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 495/495 [15:32<00:00,  1.88s/it]
Model Updated: Validation Loss Epoch: 0 Value: 4.187405576705933 Optimal_loss: 4.187405576705933
val Procedure: 24it [00:01, 17.85it/s]████████████████████████████████████████████████████████████████████████████████████████████| 495/495 [15:32<00:00,  1.78s/it]
Loss Epoch: 13 Value: 4.165480561208243
Training Procedure: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 495/495 [16:24<00:00,  1.99s/it]
Model Updated: Validation Loss Epoch: 0 Value: 4.169785194396972 Optimal_loss: 4.169785194396972
val Procedure: 24it [00:01, 17.43it/s]████████████████████████████████████████████████████████████████████████████████████████████| 495/495 [16:23<00:00,  2.14s/it]
Loss Epoch: 14 Value: 4.211669342927259
Training Procedure: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 495/495 [18:50<00:00,  2.28s/it]
val Procedure: 24it [00:01, 16.32it/s]████████████████████████████████████████████████████████████████████████████████████████████| 495/495 [18:49<00:00,  2.19s/it]
Loss Epoch: 15 Value: 4.249211192853523
Training Procedure: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 495/495 [15:55<00:00,  1.93s/it]
Model Updated: Validation Loss Epoch: 0 Value: 4.153751974105835 Optimal_loss: 4.153751974105835
val Procedure: 24it [00:01, 17.05it/s]████████████████████████████████████████████████████████████████████████████████████████████| 495/495 [15:55<00:00,  1.79s/it]
Loss Epoch: 16 Value: 4.140823910934756
Training Procedure: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 495/495 [15:36<00:00,  1.89s/it]
Model Updated: Validation Loss Epoch: 0 Value: 4.135196094512939 Optimal_loss: 4.135196094512939
val Procedure: 24it [00:01, 16.51it/s]████████████████████████████████████████████████████████████████████████████████████████████| 495/495 [15:36<00:00,  1.79s/it]
Loss Epoch: 17 Value: 4.121382872745245
Training Procedure: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 495/495 [15:34<00:00,  1.89s/it]
Model Updated: Validation Loss Epoch: 0 Value: 4.130469379425048 Optimal_loss: 4.130469379425048
val Procedure: 24it [00:01, 16.75it/s]████████████████████████████████████████████████████████████████████████████████████████████| 495/495 [15:34<00:00,  1.78s/it]
Loss Epoch: 18 Value: 4.117878687502158
Training Procedure: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 495/495 [15:35<00:00,  1.89s/it]
Model Updated: Validation Loss Epoch: 0 Value: 4.09594910621643 Optimal_loss: 4.09594910621643
val Procedure: 24it [00:01, 14.10it/s]████████████████████████████████████████████████████████████████████████████████████████████| 495/495 [15:34<00:00,  1.78s/it]
Loss Epoch: 19 Value: 4.07733763540634
Training Procedure: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 495/495 [15:39<00:00,  1.90s/it]
val Procedure: 24it [00:01, 14.46it/s]████████████████████████████████████████████████████████████████████████████████████████████| 495/495 [15:38<00:00,  1.78s/it]
Loss Epoch: 20 Value: 4.066698738541266
Training Procedure: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 495/495 [15:36<00:00,  1.89s/it]
val Procedure: 24it [00:01, 16.32it/s]████████████████████████████████████████████████████████████████████████████████████████████| 495/495 [15:36<00:00,  1.78s/it]
Loss Epoch: 21 Value: 4.0794948356320155
Training Procedure: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 495/495 [15:41<00:00,  1.90s/it]
val Procedure: 24it [00:01, 15.20it/s]████████████████████████████████████████████████████████████████████████████████████████████| 495/495 [15:40<00:00,  1.78s/it]
Loss Epoch: 22 Value: 4.066653699104232
Training Procedure: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 495/495 [15:33<00:00,  1.89s/it]
Model Updated: Validation Loss Epoch: 0 Value: 4.056676073074341 Optimal_loss: 4.056676073074341
val Procedure: 24it [00:01, 12.15it/s]████████████████████████████████████████████████████████████████████████████████████████████| 495/495 [15:33<00:00,  1.79s/it]
Loss Epoch: 23 Value: 4.043698204406584
Training Procedure: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 495/495 [15:47<00:00,  1.91s/it]
val Procedure: 24it [00:01, 16.94it/s]████████████████████████████████████████████████████████████████████████████████████████████| 495/495 [15:47<00:00,  1.78s/it]
Loss Epoch: 24 Value: 4.034552879526157
Training Procedure: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 495/495 [15:40<00:00,  1.90s/it]
Model Updated: Validation Loss Epoch: 0 Value: 4.023588781356811 Optimal_loss: 4.023588781356811
val Procedure: 24it [00:01, 18.52it/s]████████████████████████████████████████████████████████████████████████████████████████████| 495/495 [15:40<00:00,  1.79s/it]
Loss Epoch: 25 Value: 4.029604295287469
Training Procedure: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 495/495 [15:33<00:00,  1.89s/it]
val Procedure: 24it [00:01, 18.27it/s]████████████████████████████████████████████████████████████████████████████████████████████| 495/495 [15:32<00:00,  1.78s/it]
Loss Epoch: 26 Value: 4.017244997409859
Training Procedure:  35%|████████████████████████████████████▋                                                                    | 173/495 [05:29<10:14,  1.91s/it]
Model Updated: Validation Loss Epoch: 0 Value: 4.0168211555480955 Optimal_loss: 4.0168211555480955
Traceback (most recent call last):                                                                                                                                  
  File "/home/cboned/Projects/OCR-Koopman/main_classification_ode.py", line 213, in <module>
    main(cfg=cfg)
  File "/home/cboned/Projects/OCR-Koopman/main_classification_ode.py", line 131, in main
    _, train_loss = train_classification_task(
  File "/home/cboned/Projects/OCR-Koopman/train.py", line 149, in train_classification_task
    loss.backward()
  File "/home/cboned/miniconda3/envs/graphocr/lib/python3.10/site-packages/torch/_tensor.py", line 581, in backward
    torch.autograd.backward(
  File "/home/cboned/miniconda3/envs/graphocr/lib/python3.10/site-packages/torch/autograd/__init__.py", line 347, in backward
    _engine_run_backward(
  File "/home/cboned/miniconda3/envs/graphocr/lib/python3.10/site-packages/torch/autograd/graph.py", line 825, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt
