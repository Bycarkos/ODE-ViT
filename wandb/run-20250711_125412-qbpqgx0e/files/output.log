Some weights of the model checkpoint at /data/users/cboned/checkpoints/Vit_CIFAR100_first_train_reduced.pt were not used when initializing ViTForImageClassification: ['vit.encoder.layer.1.attention.attention.key.bias', 'vit.encoder.layer.1.attention.attention.key.weight', 'vit.encoder.layer.1.attention.attention.query.bias', 'vit.encoder.layer.1.attention.attention.query.weight', 'vit.encoder.layer.1.attention.attention.value.bias', 'vit.encoder.layer.1.attention.attention.value.weight', 'vit.encoder.layer.1.attention.output.dense.bias', 'vit.encoder.layer.1.attention.output.dense.weight', 'vit.encoder.layer.1.intermediate.dense.bias', 'vit.encoder.layer.1.intermediate.dense.weight', 'vit.encoder.layer.1.layernorm_after.bias', 'vit.encoder.layer.1.layernorm_after.weight', 'vit.encoder.layer.1.layernorm_before.bias', 'vit.encoder.layer.1.layernorm_before.weight', 'vit.encoder.layer.1.output.dense.bias', 'vit.encoder.layer.1.output.dense.weight', 'vit.encoder.layer.10.attention.attention.key.bias', 'vit.encoder.layer.10.attention.attention.key.weight', 'vit.encoder.layer.10.attention.attention.query.bias', 'vit.encoder.layer.10.attention.attention.query.weight', 'vit.encoder.layer.10.attention.attention.value.bias', 'vit.encoder.layer.10.attention.attention.value.weight', 'vit.encoder.layer.10.attention.output.dense.bias', 'vit.encoder.layer.10.attention.output.dense.weight', 'vit.encoder.layer.10.intermediate.dense.bias', 'vit.encoder.layer.10.intermediate.dense.weight', 'vit.encoder.layer.10.layernorm_after.bias', 'vit.encoder.layer.10.layernorm_after.weight', 'vit.encoder.layer.10.layernorm_before.bias', 'vit.encoder.layer.10.layernorm_before.weight', 'vit.encoder.layer.10.output.dense.bias', 'vit.encoder.layer.10.output.dense.weight', 'vit.encoder.layer.11.attention.attention.key.bias', 'vit.encoder.layer.11.attention.attention.key.weight', 'vit.encoder.layer.11.attention.attention.query.bias', 'vit.encoder.layer.11.attention.attention.query.weight', 'vit.encoder.layer.11.attention.attention.value.bias', 'vit.encoder.layer.11.attention.attention.value.weight', 'vit.encoder.layer.11.attention.output.dense.bias', 'vit.encoder.layer.11.attention.output.dense.weight', 'vit.encoder.layer.11.intermediate.dense.bias', 'vit.encoder.layer.11.intermediate.dense.weight', 'vit.encoder.layer.11.layernorm_after.bias', 'vit.encoder.layer.11.layernorm_after.weight', 'vit.encoder.layer.11.layernorm_before.bias', 'vit.encoder.layer.11.layernorm_before.weight', 'vit.encoder.layer.11.output.dense.bias', 'vit.encoder.layer.11.output.dense.weight', 'vit.encoder.layer.2.attention.attention.key.bias', 'vit.encoder.layer.2.attention.attention.key.weight', 'vit.encoder.layer.2.attention.attention.query.bias', 'vit.encoder.layer.2.attention.attention.query.weight', 'vit.encoder.layer.2.attention.attention.value.bias', 'vit.encoder.layer.2.attention.attention.value.weight', 'vit.encoder.layer.2.attention.output.dense.bias', 'vit.encoder.layer.2.attention.output.dense.weight', 'vit.encoder.layer.2.intermediate.dense.bias', 'vit.encoder.layer.2.intermediate.dense.weight', 'vit.encoder.layer.2.layernorm_after.bias', 'vit.encoder.layer.2.layernorm_after.weight', 'vit.encoder.layer.2.layernorm_before.bias', 'vit.encoder.layer.2.layernorm_before.weight', 'vit.encoder.layer.2.output.dense.bias', 'vit.encoder.layer.2.output.dense.weight', 'vit.encoder.layer.3.attention.attention.key.bias', 'vit.encoder.layer.3.attention.attention.key.weight', 'vit.encoder.layer.3.attention.attention.query.bias', 'vit.encoder.layer.3.attention.attention.query.weight', 'vit.encoder.layer.3.attention.attention.value.bias', 'vit.encoder.layer.3.attention.attention.value.weight', 'vit.encoder.layer.3.attention.output.dense.bias', 'vit.encoder.layer.3.attention.output.dense.weight', 'vit.encoder.layer.3.intermediate.dense.bias', 'vit.encoder.layer.3.intermediate.dense.weight', 'vit.encoder.layer.3.layernorm_after.bias', 'vit.encoder.layer.3.layernorm_after.weight', 'vit.encoder.layer.3.layernorm_before.bias', 'vit.encoder.layer.3.layernorm_before.weight', 'vit.encoder.layer.3.
- This IS expected if you are initializing ViTForImageClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing ViTForImageClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Loaded keys: <All keys matched successfully>
CREATING THE BASELINE METRIC VALUE
 STARTING TO EVALUATE FO THE FIRST TIME
Training Procedure: 100%|██████████████████████████████████████████████████████████████████████████████████████| 196/196 [16:16<00:00,  4.98s/it]
val Procedure: 24it [00:07,  3.05it/s]█████████████████████████████████████████████████████████████████████████| 196/196 [16:16<00:00,  3.85s/it]
Loss Epoch: 1 Value: 30.391290411657216
Training Procedure: 100%|██████████████████████████████████████████████████████████████████████████████████████| 196/196 [16:14<00:00,  4.97s/it]
Model Updated: Validation Loss Epoch: 0 Value: 6.361177539825439 Optimal_loss: 6.361177539825439
val Procedure: 24it [00:07,  3.11it/s]█████████████████████████████████████████████████████████████████████████| 196/196 [16:14<00:00,  4.07s/it]
Loss Epoch: 2 Value: 25.676933551321223
Training Procedure: 100%|██████████████████████████████████████████████████████████████████████████████████████| 196/196 [16:14<00:00,  4.97s/it]
Model Updated: Validation Loss Epoch: 0 Value: 5.068130722045899 Optimal_loss: 5.068130722045899
val Procedure: 24it [00:07,  3.20it/s]█████████████████████████████████████████████████████████████████████████| 196/196 [16:14<00:00,  4.08s/it]
Loss Epoch: 3 Value: 23.878970525702652
Training Procedure: 100%|██████████████████████████████████████████████████████████████████████████████████████| 196/196 [16:14<00:00,  4.97s/it]
Model Updated: Validation Loss Epoch: 0 Value: 4.6390838623046875 Optimal_loss: 4.6390838623046875
val Procedure: 24it [00:07,  3.17it/s]█████████████████████████████████████████████████████████████████████████| 196/196 [16:14<00:00,  4.08s/it]
Loss Epoch: 4 Value: 23.30764898961904
Training Procedure: 100%|██████████████████████████████████████████████████████████████████████████████████████| 196/196 [16:19<00:00,  5.00s/it]
Model Updated: Validation Loss Epoch: 0 Value: 4.4633837890625 Optimal_loss: 4.4633837890625
val Procedure: 24it [00:07,  3.30it/s]█████████████████████████████████████████████████████████████████████████| 196/196 [16:19<00:00,  4.08s/it]
Loss Epoch: 5 Value: 22.992697871461207
Training Procedure: 100%|██████████████████████████████████████████████████████████████████████████████████████| 196/196 [16:16<00:00,  4.98s/it]
Model Updated: Validation Loss Epoch: 0 Value: 4.352705173492431 Optimal_loss: 4.352705173492431
val Procedure: 24it [00:07,  3.19it/s]█████████████████████████████████████████████████████████████████████████| 196/196 [16:16<00:00,  4.09s/it]
Loss Epoch: 6 Value: 22.671427240177078
Training Procedure: 100%|██████████████████████████████████████████████████████████████████████████████████████| 196/196 [16:16<00:00,  4.98s/it]
Model Updated: Validation Loss Epoch: 0 Value: 4.306055192947388 Optimal_loss: 4.306055192947388
val Procedure: 24it [00:07,  3.18it/s]█████████████████████████████████████████████████████████████████████████| 196/196 [16:16<00:00,  4.07s/it]
Loss Epoch: 7 Value: 22.27903817624462
Training Procedure: 100%|██████████████████████████████████████████████████████████████████████████████████████| 196/196 [16:15<00:00,  4.98s/it]
Model Updated: Validation Loss Epoch: 0 Value: 4.075165929794312 Optimal_loss: 4.075165929794312
val Procedure: 24it [00:08,  3.00it/s]█████████████████████████████████████████████████████████████████████████| 196/196 [16:15<00:00,  4.08s/it]
Loss Epoch: 8 Value: 21.84799086317724
Training Procedure: 100%|██████████████████████████████████████████████████████████████████████████████████████| 196/196 [16:15<00:00,  4.98s/it]
Model Updated: Validation Loss Epoch: 0 Value: 4.002864084243774 Optimal_loss: 4.002864084243774
val Procedure: 24it [00:08,  2.95it/s]█████████████████████████████████████████████████████████████████████████| 196/196 [16:15<00:00,  4.08s/it]
Loss Epoch: 9 Value: 21.443832144445302
Training Procedure: 100%|██████████████████████████████████████████████████████████████████████████████████████| 196/196 [16:15<00:00,  4.98s/it]
Model Updated: Validation Loss Epoch: 0 Value: 3.8101268196105957 Optimal_loss: 3.8101268196105957
val Procedure: 24it [00:07,  3.03it/s]█████████████████████████████████████████████████████████████████████████| 196/196 [16:15<00:00,  4.08s/it]
Loss Epoch: 10 Value: 21.05657551239948
Training Procedure: 100%|██████████████████████████████████████████████████████████████████████████████████████| 196/196 [16:21<00:00,  5.01s/it]
val Procedure: 24it [00:07,  3.07it/s]█████████████████████████████████████████████████████████████████████████| 196/196 [16:21<00:00,  4.06s/it]
Loss Epoch: 11 Value: 20.71756062215688
Training Procedure: 100%|██████████████████████████████████████████████████████████████████████████████████████| 196/196 [16:16<00:00,  4.98s/it]
Model Updated: Validation Loss Epoch: 0 Value: 3.6605863189697265 Optimal_loss: 3.6605863189697265
val Procedure: 24it [00:07,  3.19it/s]█████████████████████████████████████████████████████████████████████████| 196/196 [16:16<00:00,  4.08s/it]
Loss Epoch: 12 Value: 20.394542334031087
Training Procedure: 100%|██████████████████████████████████████████████████████████████████████████████████████| 196/196 [16:15<00:00,  4.98s/it]
val Procedure: 24it [00:08,  2.96it/s]█████████████████████████████████████████████████████████████████████████| 196/196 [16:15<00:00,  4.09s/it]
Loss Epoch: 13 Value: 20.106529080137914
Training Procedure: 100%|██████████████████████████████████████████████████████████████████████████████████████| 196/196 [16:15<00:00,  4.98s/it]
Model Updated: Validation Loss Epoch: 0 Value: 3.594066104888916 Optimal_loss: 3.594066104888916
val Procedure: 24it [00:08,  2.94it/s]█████████████████████████████████████████████████████████████████████████| 196/196 [16:15<00:00,  4.08s/it]
Loss Epoch: 14 Value: 19.80573911082988
Training Procedure: 100%|██████████████████████████████████████████████████████████████████████████████████████| 196/196 [16:16<00:00,  4.98s/it]
Model Updated: Validation Loss Epoch: 0 Value: 3.462618141174316 Optimal_loss: 3.462618141174316
val Procedure: 24it [00:07,  3.19it/s]█████████████████████████████████████████████████████████████████████████| 196/196 [16:16<00:00,  4.08s/it]
Loss Epoch: 15 Value: 19.5376191528476
Training Procedure: 100%|██████████████████████████████████████████████████████████████████████████████████████| 196/196 [16:20<00:00,  5.00s/it]
val Procedure: 24it [00:07,  3.08it/s]█████████████████████████████████████████████████████████████████████████| 196/196 [16:20<00:00,  4.08s/it]
Loss Epoch: 16 Value: 19.26723676798295
Training Procedure: 100%|██████████████████████████████████████████████████████████████████████████████████████| 196/196 [16:17<00:00,  4.98s/it]
Model Updated: Validation Loss Epoch: 0 Value: 3.3855045795440675 Optimal_loss: 3.3855045795440675
val Procedure: 24it [00:07,  3.02it/s]█████████████████████████████████████████████████████████████████████████| 196/196 [16:16<00:00,  4.08s/it]
Loss Epoch: 17 Value: 19.019669853911108
Training Procedure: 100%|██████████████████████████████████████████████████████████████████████████████████████| 196/196 [16:16<00:00,  4.98s/it]
Model Updated: Validation Loss Epoch: 0 Value: 3.378515615463257 Optimal_loss: 3.378515615463257
val Procedure: 24it [00:07,  3.15it/s]█████████████████████████████████████████████████████████████████████████| 196/196 [16:16<00:00,  4.08s/it]
Loss Epoch: 18 Value: 18.8014686934802
Training Procedure: 100%|██████████████████████████████████████████████████████████████████████████████████████| 196/196 [16:16<00:00,  4.98s/it]
val Procedure: 24it [00:07,  3.16it/s]█████████████████████████████████████████████████████████████████████████| 196/196 [16:16<00:00,  4.08s/it]
Loss Epoch: 19 Value: 18.5887040410723
Training Procedure: 100%|██████████████████████████████████████████████████████████████████████████████████████| 196/196 [16:16<00:00,  4.98s/it]
Model Updated: Validation Loss Epoch: 0 Value: 3.277567777633667 Optimal_loss: 3.277567777633667
val Procedure: 24it [00:07,  3.19it/s]█████████████████████████████████████████████████████████████████████████| 196/196 [16:16<00:00,  4.08s/it]
Loss Epoch: 20 Value: 18.39014820176728
Training Procedure: 100%|██████████████████████████████████████████████████████████████████████████████████████| 196/196 [16:17<00:00,  4.99s/it]
Model Updated: Validation Loss Epoch: 0 Value: 3.2099764823913572 Optimal_loss: 3.2099764823913572
val Procedure: 24it [00:07,  3.12it/s]█████████████████████████████████████████████████████████████████████████| 196/196 [16:17<00:00,  4.06s/it]
Loss Epoch: 21 Value: 18.21215534210205
Training Procedure: 100%|██████████████████████████████████████████████████████████████████████████████████████| 196/196 [16:22<00:00,  5.01s/it]
val Procedure: 24it [00:07,  3.16it/s]█████████████████████████████████████████████████████████████████████████| 196/196 [16:22<00:00,  4.08s/it]
Loss Epoch: 22 Value: 18.054556603334387
Training Procedure: 100%|██████████████████████████████████████████████████████████████████████████████████████| 196/196 [16:17<00:00,  4.99s/it]
val Procedure: 24it [00:07,  3.20it/s]█████████████████████████████████████████████████████████████████████████| 196/196 [16:17<00:00,  4.08s/it]
Loss Epoch: 23 Value: 17.89451907605541
Training Procedure: 100%|██████████████████████████████████████████████████████████████████████████████████████| 196/196 [16:16<00:00,  4.98s/it]
Model Updated: Validation Loss Epoch: 0 Value: 3.1069273281097414 Optimal_loss: 3.1069273281097414
val Procedure: 24it [00:07,  3.09it/s]█████████████████████████████████████████████████████████████████████████| 196/196 [16:16<00:00,  4.08s/it]
Loss Epoch: 24 Value: 17.76065882857965
Training Procedure: 100%|██████████████████████████████████████████████████████████████████████████████████████| 196/196 [16:18<00:00,  4.99s/it]
val Procedure: 24it [00:07,  3.00it/s]█████████████████████████████████████████████████████████████████████████| 196/196 [16:18<00:00,  4.09s/it]
Loss Epoch: 25 Value: 17.66370914420303
Training Procedure: 100%|██████████████████████████████████████████████████████████████████████████████████████| 196/196 [16:18<00:00,  4.99s/it]
val Procedure: 24it [00:07,  3.18it/s]█████████████████████████████████████████████████████████████████████████| 196/196 [16:18<00:00,  4.09s/it]
Loss Epoch: 26 Value: 17.527654764603597
Training Procedure: 100%|██████████████████████████████████████████████████████████████████████████████████████| 196/196 [16:19<00:00,  5.00s/it]
val Procedure: 24it [00:07,  3.03it/s]█████████████████████████████████████████████████████████████████████████| 196/196 [16:19<00:00,  4.07s/it]
Loss Epoch: 27 Value: 17.448590327282343
Training Procedure: 100%|██████████████████████████████████████████████████████████████████████████████████████| 196/196 [16:16<00:00,  4.98s/it]
Model Updated: Validation Loss Epoch: 0 Value: 3.0914372253417968 Optimal_loss: 3.0914372253417968
val Procedure: 24it [00:07,  3.18it/s]█████████████████████████████████████████████████████████████████████████| 196/196 [16:16<00:00,  4.08s/it]
Loss Epoch: 28 Value: 17.54062608796723
Training Procedure: 100%|██████████████████████████████████████████████████████████████████████████████████████| 196/196 [16:18<00:00,  4.99s/it]
Model Updated: Validation Loss Epoch: 0 Value: 3.0201730728149414 Optimal_loss: 3.0201730728149414
val Procedure: 24it [00:07,  3.09it/s]█████████████████████████████████████████████████████████████████████████| 196/196 [16:18<00:00,  4.09s/it]
Loss Epoch: 29 Value: 19.021553779134944
Training Procedure: 100%|██████████████████████████████████████████████████████████████████████████████████████| 196/196 [08:59<00:00,  2.75s/it]
val Procedure: 24it [00:02, 10.72it/s]█████████████████████████████████████████████████████████████████████████| 196/196 [08:58<00:00,  2.19s/it]
Loss Epoch: 30 Value: 49.91038477177523
Training Procedure:  66%|████████████████████████████████████████████████████████▌                             | 129/196 [04:49<02:30,  2.25s/it]
Traceback (most recent call last):                                                                                                               
  File "/home/cboned/Projects/OCR-Koopman/main_classification_with_koopman.py", line 224, in <module>
  File "/home/cboned/Projects/OCR-Koopman/main_classification_with_koopman.py", line 162, in main
  File "/home/cboned/Projects/OCR-Koopman/train.py", line 93, in train_classification_with_koopman
  File "/home/cboned/miniconda3/envs/graphocr/lib/python3.10/site-packages/torch/_tensor.py", line 581, in backward
    torch.autograd.backward(
  File "/home/cboned/miniconda3/envs/graphocr/lib/python3.10/site-packages/torch/autograd/__init__.py", line 347, in backward
    _engine_run_backward(
  File "/home/cboned/miniconda3/envs/graphocr/lib/python3.10/site-packages/torch/autograd/graph.py", line 825, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt
