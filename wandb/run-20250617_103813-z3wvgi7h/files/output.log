Config of the encoder: <class 'transformers.models.vit.modeling_vit.ViTModel'> is overwritten by shared encoder config: ViTConfig {
  "attention_probs_dropout_prob": 0.0,
  "encoder_stride": 16,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.0,
  "hidden_size": 768,
  "image_size": 384,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "model_type": "vit",
  "num_attention_heads": 12,
  "num_channels": 3,
  "num_hidden_layers": 1,
  "patch_size": 16,
  "pooler_act": "tanh",
  "pooler_output_size": 768,
  "qkv_bias": false,
  "torch_dtype": "float32",
  "transformers_version": "4.51.1"
}

Config of the decoder: <class 'transformers.models.trocr.modeling_trocr.TrOCRForCausalLM'> is overwritten by shared decoder config: TrOCRConfig {
  "activation_dropout": 0.0,
  "activation_function": "relu",
  "add_cross_attention": true,
  "attention_dropout": 0.0,
  "bos_token_id": 0,
  "classifier_dropout": 0.0,
  "cross_attention_hidden_size": 768,
  "d_model": 1024,
  "decoder_attention_heads": 16,
  "decoder_ffn_dim": 4096,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 12,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "eos_token_id": 2,
  "init_std": 0.02,
  "is_decoder": true,
  "layernorm_embedding": false,
  "max_position_embeddings": 1024,
  "model_type": "trocr",
  "pad_token_id": 1,
  "scale_embedding": true,
  "tie_word_embeddings": false,
  "torch_dtype": "float32",
  "transformers_version": "4.51.1",
  "use_cache": false,
  "use_learned_position_embeddings": false,
  "vocab_size": 50265
}

Some weights of the model checkpoint at checkpoints/TrOCR_Esposalles_reduced.pt were not used when initializing VisionEncoderDecoderModel: ['encoder.encoder.layer.1.attention.attention.key.weight', 'encoder.encoder.layer.1.attention.attention.query.weight', 'encoder.encoder.layer.1.attention.attention.value.weight', 'encoder.encoder.layer.1.attention.output.dense.bias', 'encoder.encoder.layer.1.attention.output.dense.weight', 'encoder.encoder.layer.1.intermediate.dense.bias', 'encoder.encoder.layer.1.intermediate.dense.weight', 'encoder.encoder.layer.1.layernorm_after.bias', 'encoder.encoder.layer.1.layernorm_after.weight', 'encoder.encoder.layer.1.layernorm_before.bias', 'encoder.encoder.layer.1.layernorm_before.weight', 'encoder.encoder.layer.1.output.dense.bias', 'encoder.encoder.layer.1.output.dense.weight', 'encoder.encoder.layer.10.attention.attention.key.weight', 'encoder.encoder.layer.10.attention.attention.query.weight', 'encoder.encoder.layer.10.attention.attention.value.weight', 'encoder.encoder.layer.10.attention.output.dense.bias', 'encoder.encoder.layer.10.attention.output.dense.weight', 'encoder.encoder.layer.10.intermediate.dense.bias', 'encoder.encoder.layer.10.intermediate.dense.weight', 'encoder.encoder.layer.10.layernorm_after.bias', 'encoder.encoder.layer.10.layernorm_after.weight', 'encoder.encoder.layer.10.layernorm_before.bias', 'encoder.encoder.layer.10.layernorm_before.weight', 'encoder.encoder.layer.10.output.dense.bias', 'encoder.encoder.layer.10.output.dense.weight', 'encoder.encoder.layer.11.attention.attention.key.weight', 'encoder.encoder.layer.11.attention.attention.query.weight', 'encoder.encoder.layer.11.attention.attention.value.weight', 'encoder.encoder.layer.11.attention.output.dense.bias', 'encoder.encoder.layer.11.attention.output.dense.weight', 'encoder.encoder.layer.11.intermediate.dense.bias', 'encoder.encoder.layer.11.intermediate.dense.weight', 'encoder.encoder.layer.11.layernorm_after.bias', 'encoder.encoder.layer.11.layernorm_after.weight', 'encoder.encoder.layer.11.layernorm_before.bias', 'encoder.encoder.layer.11.layernorm_before.weight', 'encoder.encoder.layer.11.output.dense.bias', 'encoder.encoder.layer.11.output.dense.weight', 'encoder.encoder.layer.2.attention.attention.key.weight', 'encoder.encoder.layer.2.attention.attention.query.weight', 'encoder.encoder.layer.2.attention.attention.value.weight', 'encoder.encoder.layer.2.attention.output.dense.bias', 'encoder.encoder.layer.2.attention.output.dense.weight', 'encoder.encoder.layer.2.intermediate.dense.bias', 'encoder.encoder.layer.2.intermediate.dense.weight', 'encoder.encoder.layer.2.layernorm_after.bias', 'encoder.encoder.layer.2.layernorm_after.weight', 'encoder.encoder.layer.2.layernorm_before.bias', 'encoder.encoder.layer.2.layernorm_before.weight', 'encoder.encoder.layer.2.output.dense.bias', 'encoder.encoder.layer.2.output.dense.weight', 'encoder.encoder.layer.3.attention.attention.key.weight', 'encoder.encoder.layer.3.attention.attention.query.weight', 'encoder.encoder.layer.3.attention.attention.value.weight', 'encoder.encoder.layer.3.attention.output.dense.bias', 'encoder.encoder.layer.3.attention.output.dense.weight', 'encoder.encoder.layer.3.intermediate.dense.bias', 'encoder.encoder.layer.3.intermediate.dense.weight', 'encoder.encoder.layer.3.layernorm_after.bias', 'encoder.encoder.layer.3.layernorm_after.weight', 'encoder.encoder.layer.3.layernorm_before.bias', 'encoder.encoder.layer.3.layernorm_before.weight', 'encoder.encoder.layer.3.output.dense.bias', 'encoder.encoder.layer.3.output.dense.weight', 'encoder.encoder.layer.4.attention.attention.key.weight', 'encoder.encoder.layer.4.attention.attention.query.weight', 'encoder.encoder.layer.4.attention.attention.value.weight', 'encoder.encoder.layer.4.attention.output.dense.bias', 'encoder.encoder.layer.4.attention.output.dense.weight', 'encoder.encoder.layer.4.intermediate.dense.bias', 'encoder.encoder.layer.4.intermediate.dense.weight', 'encoder.encoder.layer.4.layernorm_after.bias', 'encoder.encoder.layer.4.layernorm_after.weight', 'encoder.encoder.l
- This IS expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing VisionEncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
/home/cboned/Projects/OCR-Koopman/experiment_ocr_lkis_ctc.py:38: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  keys = torch.load("checkpoints/TrOCR_Esposalles_CTC_With_Q_2.pt")
Reduced model loaded
Loaded keys: <All keys matched successfully>
LKIS model loaded
Starting training procedure
Evaluating to get the baseline
val Procedure: 24it [01:17,  3.23s/it]
Training Epoch 1: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 345/345 [03:47<00:00,  1.52it/s]
Validation Loss Epoch: 0 Value: 74.26488708496093 Optimal_loss: 74.26488708496093
val Procedure: 9it [00:31,  3.53s/it]████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 345/345 [03:47<00:00,  1.78it/s]
Loss Epoch: 1 Value: 0.0754901902211411
Training Epoch 2: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 345/345 [03:44<00:00,  1.54it/s]
Model Updated: Validation Loss Epoch: 0 Value: 5.444797325134277 Optimal_loss: 5.444797325134277
val Procedure: 9it [00:31,  3.52s/it]████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 345/345 [03:44<00:00,  1.78it/s]
Loss Epoch: 2 Value: 0.011573608208543938
Training Epoch 3: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 345/345 [03:45<00:00,  1.53it/s]
Model Updated: Validation Loss Epoch: 0 Value: 2.43019859790802 Optimal_loss: 2.43019859790802
val Procedure: 9it [00:31,  3.52s/it]████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 345/345 [03:45<00:00,  1.78it/s]
Loss Epoch: 3 Value: 0.006077377240814549
Training Epoch 4: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 345/345 [03:45<00:00,  1.53it/s]
Model Updated: Validation Loss Epoch: 0 Value: 1.6884111285209655 Optimal_loss: 1.6884111285209655
val Procedure: 9it [00:31,  3.52s/it]████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 345/345 [03:45<00:00,  1.78it/s]
Loss Epoch: 4 Value: 0.0049929704838404
Training Epoch 5: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 345/345 [03:45<00:00,  1.53it/s]
Model Updated: Validation Loss Epoch: 0 Value: 1.4731227278709411 Optimal_loss: 1.4731227278709411
val Procedure: 9it [00:31,  3.53s/it]████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 345/345 [03:45<00:00,  1.77it/s]
Loss Epoch: 5 Value: 0.004475750876083967
Training Epoch 6: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 345/345 [03:45<00:00,  1.53it/s]
Model Updated: Validation Loss Epoch: 0 Value: 1.3776739239692688 Optimal_loss: 1.3776739239692688
val Procedure: 9it [00:31,  3.51s/it]████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 345/345 [03:45<00:00,  1.78it/s]
Loss Epoch: 6 Value: 0.004173291460152209
Training Epoch 7: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 345/345 [03:45<00:00,  1.53it/s]
Model Updated: Validation Loss Epoch: 0 Value: 1.2824763178825378 Optimal_loss: 1.2824763178825378
val Procedure: 9it [00:31,  3.53s/it]████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 345/345 [03:45<00:00,  1.77it/s]
Loss Epoch: 7 Value: 0.003954379821469668
Training Epoch 8: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 345/345 [03:45<00:00,  1.53it/s]
Model Updated: Validation Loss Epoch: 0 Value: 1.2138553500175475 Optimal_loss: 1.2138553500175475
val Procedure: 9it [00:31,  3.54s/it]████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 345/345 [03:45<00:00,  1.78it/s]
Loss Epoch: 8 Value: 0.0037959296812006614
Training Epoch 9: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 345/345 [03:45<00:00,  1.53it/s]
Model Updated: Validation Loss Epoch: 0 Value: 1.190295147895813 Optimal_loss: 1.190295147895813
val Procedure: 9it [00:31,  3.52s/it]████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 345/345 [03:45<00:00,  1.78it/s]
Loss Epoch: 9 Value: 0.003656946129970154
Training Epoch 10: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 345/345 [03:44<00:00,  1.54it/s]
val Procedure: 9it [00:31,  3.52s/it]████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 345/345 [03:44<00:00,  1.78it/s]
Loss Epoch: 10 Value: 0.003570277241693027
Training Epoch 11: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 345/345 [03:45<00:00,  1.53it/s]
Model Updated: Validation Loss Epoch: 0 Value: 1.1247001886367798 Optimal_loss: 1.1247001886367798
val Procedure: 9it [00:31,  3.54s/it]████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 345/345 [03:45<00:00,  1.78it/s]
Loss Epoch: 11 Value: 0.0034481995703166987
Training Epoch 12: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 345/345 [03:45<00:00,  1.53it/s]
Model Updated: Validation Loss Epoch: 0 Value: 1.1015501260757445 Optimal_loss: 1.1015501260757445
val Procedure: 9it [00:31,  3.52s/it]████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 345/345 [03:45<00:00,  1.78it/s]
Loss Epoch: 12 Value: 0.0033911543136833848
Training Epoch 13: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 345/345 [03:45<00:00,  1.53it/s]
Model Updated: Validation Loss Epoch: 0 Value: 0.9848214030265808 Optimal_loss: 0.9848214030265808
val Procedure: 9it [00:31,  3.52s/it]████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 345/345 [03:45<00:00,  1.78it/s]
Loss Epoch: 13 Value: 0.003275605293663328
Training Epoch 14: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 345/345 [03:45<00:00,  1.53it/s]
val Procedure: 9it [00:31,  3.51s/it]████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 345/345 [03:45<00:00,  1.78it/s]
Loss Epoch: 14 Value: 0.0031921541853578016
Training Epoch 15: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 345/345 [03:45<00:00,  1.53it/s]
val Procedure: 9it [00:31,  3.51s/it]████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 345/345 [03:45<00:00,  1.78it/s]
Loss Epoch: 15 Value: 0.003145286999838464
Training Epoch 16: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 345/345 [03:45<00:00,  1.53it/s]
val Procedure: 9it [00:31,  3.51s/it]████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 345/345 [03:45<00:00,  1.78it/s]
Loss Epoch: 16 Value: 0.003054801945525091
Training Epoch 17:  89%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                | 306/345 [03:20<00:25,  1.52it/s]
Traceback (most recent call last):                                                                                                                                                                     
  File "/home/cboned/Projects/OCR-Koopman/experiment_ocr_lkis_ctc.py", line 468, in <module>
    main(cfg=cfg)
  File "/home/cboned/Projects/OCR-Koopman/experiment_ocr_lkis_ctc.py", line 385, in main
    _, metrics = train_one_epoch(
  File "/home/cboned/Projects/OCR-Koopman/experiment_ocr_lkis_ctc.py", line 218, in train_one_epoch
    generated_ids = ctc_decoder(to_generate.detach().cpu().numpy())
KeyboardInterrupt
