log_wandb: True

finetunne:
    recover_training: False
    checkpoint: /data/users/cboned/checkpoints/EDO_DISTILLATION_VIT_ON_CIFAR10_DINO_ATTENTION_KL_LOSS_FULL_PATH.pt

setup:
    dict:
        jasmin_k: 10
        epochs: 300
        accumulation_steps: -1
        log_every: 10
        temperature: 3.0
        lambda_param: 0.25
        mse_full_path: True
        use_mse_loss: True
        use_supervision: False
        use_distillation: True
        use_kl_loss: False
        compute_per_head: False
        use_jasmin: True
        curriculum: False
        patience_factor: 0.5

    wandb:
        project: Koopman
        group: CLASSIFICATION
        name: EDO_DISTILLATION_VIT_ON_Imagenet100_DINO_ATTENTION_L1_JASMIN_FULL_PATH

data:
    dataset:
        name: "imagenet100"
        dataset_path: "/data/users/cboned/imagenet100"

    collator:
        train:
            shuffle: True
            batch_size: 64
            pin_memory: True
            num_workers: 8
            drop_last: True

        val:
            shuffle: True
            batch_size: 256
            pin_memory: False
            num_workers: 8

        test:
            shuffle: False
            batch_size: 1
            pin_memory: False
            num_workers: 0

modeling:
    type: vit

    teacher:
        checkpoint_path: "checkpoints/Vit_Imagenet100_DINO_JASMIN.pt"

    student:
        inputs:
            img_size: 224
            patch_size: 16
            in_chans: 3
            num_classes: 100
            embed_dim: 768
            num_heads: 12
            mlp_ratio: 4.0
            emulate_depth: 12.0
            time_interval: 1.0
            num_eval_steps: 24
            attn_drop: 0.1
            proj_drop: 0.1
            mlp_drop: 0.1
            l2_attention: False
            add_distillation_token: False
            register_tokens: 10
            pos_embed_register_tokens: False
            solver: "euler"

        checkpoint_name: "EDO_DISTILLATION_VIT_ON_Imagenet100_DINO_ATTENTION_L1_JASMIN_FULL_PATH"
