{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3736c678",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import torch\n",
    "import tqdm\n",
    "import wandb\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "import utils\n",
    "import lkis as LKIS\n",
    "from datasets import Collator\n",
    "\n",
    "from torch_pca import PCA\n",
    "import os\n",
    "\n",
    "from torchvision.datasets.imagenet import ImageFolder\n",
    "from torchvision.datasets import CIFAR100\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from models.wrapper_models import ResNetForKoopmanEstimation\n",
    "from transformers import ViTForImageClassification, AutoImageProcessor , ViTImageProcessor\n",
    "\n",
    "from omegaconf import DictConfig\n",
    "from hydra import initialize, compose\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a405102b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Matplotlib style\n",
    "plt.style.use(\"seaborn-v0_8-deep\")\n",
    "plt.rcParams.update(\n",
    "    {\n",
    "        \"font.size\": 12,\n",
    "        \"axes.titlesize\": 14,\n",
    "        \"axes.labelsize\": 13,\n",
    "        \"legend.fontsize\": 11,\n",
    "        \"figure.dpi\": 300,\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36d8659c",
   "metadata": {},
   "outputs": [],
   "source": [
    "STUDENT_CHECKPOINT_PATH = \"\"\n",
    "TEACHER_CHECKPOINT_PATH = \"/data/users/cboned/checkpoints/Vit_CIFAR100_first_train.pt\"\n",
    "DATASET_PATH = \"/data/users/cboned/data/Generic/cifar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e61cb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CIFAR100(root=DATASET_PATH, download=False, train=True)\n",
    "validation_dataset = CIFAR100(root=DATASET_PATH, download=False, train=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbf3e0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_model = ViTForImageClassification.from_pretrained(TEACHER_CHECKPOINT_PATH)\n",
    "\n",
    "\n",
    "processor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224-in21k')\n",
    "collator = Collator(processor)\n",
    "teacher_model.to(device)\n",
    "train_dloader = DataLoader(train_dataset, \n",
    "                           shuffle=True,\n",
    "                           batch_size=64,\n",
    "                           pin_memory=False,\n",
    "                           num_workers=0,\n",
    "                           collate_fn=collator.classification_collate_fn\n",
    "                           )\n",
    "\n",
    "\n",
    "test_dloader = DataLoader(validation_dataset,\n",
    "                          batch_size=1,\n",
    "                          pin_memory=False,\n",
    "                          num_workers=0,\n",
    "                          shuffle=True,\n",
    "                          collate_fn=collator.classification_collate_fn\n",
    "\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f96061d",
   "metadata": {},
   "source": [
    "## Computing the UEV decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0592761",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import seaborn as sns\n",
    "import imageio\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def plot_trajectory_with_vector_field(traj_batch, out_folder, out_name:str=\"merged_trajectories.png\",  image_indices=None, merged=False):\n",
    "    os.makedirs(out_folder, exist_ok=True)\n",
    "\n",
    "    n_images = traj_batch.shape[0]\n",
    "    steps = traj_batch.shape[1]\n",
    "\n",
    "    if merged:\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        for img_idx in range(n_images):\n",
    "            traj = traj_batch[img_idx]\n",
    "            x, y = traj[:, 0], traj[:, 1]\n",
    "            dx = x[1:] - x[:-1]\n",
    "            dy = y[1:] - y[:-1]\n",
    "\n",
    "            plt.plot(x, y, label=f\"Img {img_idx}\", alpha=0.7)\n",
    "            plt.quiver(x[:-1], y[:-1], dx, dy, angles='xy', scale_units='xy', scale=0.5, alpha=0.1)\n",
    "\n",
    "        plt.title(\"Merged Koopman Trajectories + Phase Arrows\")\n",
    "        plt.xlabel(\"PCA Dim 1\")\n",
    "        plt.ylabel(\"PCA Dim 2\")\n",
    "        plt.axis(\"equal\")\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(out_folder, out_name))\n",
    "        plt.close()\n",
    "\n",
    "    else:\n",
    "        for img_idx in (image_indices if image_indices is not None else range(n_images)):\n",
    "            traj = traj_batch[img_idx]\n",
    "            x, y = traj[:, 0], traj[:, 1]\n",
    "            dx = x[1:] - x[:-1]\n",
    "            dy = y[1:] - y[:-1]\n",
    "\n",
    "            plt.figure(figsize=(6, 5))\n",
    "            plt.plot(x, y, marker=\"o\", label=\"Trajectory\")\n",
    "            plt.quiver(x[:-1], y[:-1], dx, dy, angles='xy', scale_units='xy', scale=1, color=\"red\", label=\"Flow\")\n",
    "\n",
    "            for step_idx in range(len(x)):\n",
    "                plt.text(x[step_idx], y[step_idx], str(step_idx), fontsize=8)\n",
    "\n",
    "            plt.title(f\"Trajectory + Phase Flow (Image {img_idx})\")\n",
    "            plt.xlabel(\"PCA Dim 1\")\n",
    "            plt.ylabel(\"PCA Dim 2\")\n",
    "            plt.axis(\"equal\")\n",
    "            plt.grid(True)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(out_folder, f\"trajectory_image_{img_idx}.png\"))\n",
    "            plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1cf03648",
   "metadata": {},
   "outputs": [],
   "source": [
    "Vt_dictionary = defaultdict()\n",
    "cls_vt_dictionary = defaultdict(dict)\n",
    "features_to_keep = defaultdict(list)\n",
    "features_to_keep_per_class = defaultdict(list)\n",
    "\n",
    "fet_to_keep_general = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2fdeeccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting the PCA Vt for computing the trajectories:   4%|▍         | 32/782 [00:08<03:26,  3.63it/s]\n"
     ]
    }
   ],
   "source": [
    "for batch_idx, data in tqdm.tqdm(\n",
    "    enumerate(train_dloader),\n",
    "    desc=\"Extracting the PCA Vt for computing the trajectories\",\n",
    "    total=len(train_dloader),\n",
    "):\n",
    "    \n",
    "    inputs: dict = data[\"pixel_values\"].to(device)\n",
    "    labels: list = data[\"labels\"].to(device)\n",
    "    with torch.no_grad():\n",
    "        features = teacher_model(**inputs, output_hidden_states=True)[\"hidden_states\"]\n",
    "        for idx, feat in enumerate(features):\n",
    "            #feat2 = feat.reshape(-1, 768)\n",
    "            features_to_keep[idx].append(feat[:, 0])\n",
    "            fet_to_keep_general.append(feat[:, 0])\n",
    "    \n",
    "    if (batch_idx * feat.shape[0]) >= 2000:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0f6a34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(features_to_keep)):\n",
    "    embeddings_to_compute_pca = torch.cat(features_to_keep[idx], dim=0)\n",
    "    U_i, S_i, Vt_i = utils.perform_pca_lowrank(embeddings_to_compute_pca, n_eigenvectors=2, center=False)\n",
    "\n",
    "    Vt_dictionary[i] = Vt_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7003c2d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Procedure:  10%|█         | 1000/10000 [00:06<00:56, 158.99it/s]\n"
     ]
    }
   ],
   "source": [
    "teacher_model.eval()\n",
    "merged_traj = []\n",
    "for batch_idx, data in tqdm.tqdm(\n",
    "    enumerate(test_dloader),\n",
    "    desc=\"Training Procedure\",\n",
    "    total=len(test_dloader),\n",
    "):\n",
    "    \n",
    "    inputs: dict = data[\"pixel_values\"].to(device)\n",
    "    images = data[\"raw_images\"]\n",
    "    with torch.no_grad():\n",
    "        features = teacher_model(**inputs, output_hidden_states=True)[\"hidden_states\"]\n",
    "    features_cls_trajectory = torch.cat(\n",
    "        [feat.unsqueeze(1) for feat in features], dim=1\n",
    "    )[:, :, 0]\n",
    "    b, seq, d = features_cls_trajectory.shape\n",
    "    trajectories_observation = []\n",
    "    trajectories_from_vision = []\n",
    "    for i in range(seq):\n",
    "        trajectory_from_vision_encoder = utils.project_onto_subspace(\n",
    "            A=features_cls_trajectory[:, i], Vt=Vt_dictionary[i], k=2\n",
    "    )\n",
    "        trajectories_from_vision.append(trajectory_from_vision_encoder)\n",
    "    \n",
    "    traj_teacher = torch.cat(trajectories_from_vision, dim=0).cpu().numpy()\n",
    "    \n",
    "    merged_traj.append(traj_teacher[None, :])\n",
    "\n",
    "    if batch_idx >= 1000:\n",
    "        break\n",
    "\n",
    "\n",
    "merged_traj = np.concatenate(merged_traj, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "edf8cb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_vector_field_from_koopman(traj_batch, out_path=\"vector_field.png\", density=1.2):\n",
    "    traj = traj_batch.reshape(-1, 2)\n",
    "    x, y = traj[:, 0], traj[:, 1]\n",
    "\n",
    "    # Build coarse grid\n",
    "    x_grid = np.linspace(x.min()-1, x.max()+1, 30)\n",
    "    y_grid = np.linspace(y.min()-1, y.max()+1, 30)\n",
    "    X, Y = np.meshgrid(x_grid, y_grid)\n",
    "\n",
    "    # Estimate velocity vectors at grid points via local average\n",
    "    U, V = np.zeros_like(X), np.zeros_like(Y)\n",
    "    for i in range(len(x) - 1):\n",
    "        xi, yi = x[i], y[i]\n",
    "        dxi, dyi = x[i+1] - x[i], y[i+1] - y[i]\n",
    "\n",
    "        dist = (X - xi)**2 + (Y - yi)**2\n",
    "        weight = np.exp(-dist / 0.5)\n",
    "        U += weight * dxi\n",
    "        V += weight * dyi\n",
    "\n",
    "    # Compute magnitude\n",
    "    magnitude = np.sqrt(U**2 + V**2)\n",
    "\n",
    "    # Find possible attractors (lowest 5% magnitude)\n",
    "    print(np.percentile(magnitude, 99))\n",
    "    attractor_mask = magnitude > np.percentile(magnitude, 99)\n",
    "    attractor_x = X[attractor_mask]\n",
    "    attractor_y = Y[attractor_mask]\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 8))\n",
    "\n",
    "    # 1. Magnitude heatmap\n",
    "    plt.contourf(X, Y, magnitude, levels=40, cmap=\"Blues\", alpha=0.6)\n",
    "\n",
    "    # 2. Streamlines\n",
    "    plt.streamplot(X, Y, U, V, color=magnitude, linewidth=1.5, cmap=\"viridis\", density=density)\n",
    "\n",
    "    # 4. Attractor candidates\n",
    "    plt.scatter(attractor_x, attractor_y, color=\"red\", s=40, label=\"Possible Attractors\")\n",
    "\n",
    "    # Labels and final formatting\n",
    "    plt.xlabel(\"PCA Dim 1\")\n",
    "    plt.ylabel(\"PCA Dim 2\")\n",
    "    plt.colorbar(label=\"Vector Magnitude\")\n",
    "    plt.title(\"Koopman-Inferred Vector Field and Attractors\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_path)\n",
    "    plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f07d3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_out_folder = \"./koopman_phase_plots_vit\"\n",
    "out_name = f\"merge_trajectories_cls.png\"\n",
    "#plot_trajectory_with_vector_field(traj_batch=merged_traj, out_folder=plot_out_folder, merged=False)\n",
    "plot_trajectory_with_vector_field(traj_batch=merged_traj, out_folder=plot_out_folder, out_name=out_name, merged=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5df9cd65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.147421866351873\n"
     ]
    }
   ],
   "source": [
    "plot_vector_field_from_koopman(merged_traj, out_path=f\"koopman_phase_plots_vit/vector_field_cls.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45611c1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graphocr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
